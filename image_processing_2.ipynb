{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a4fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145e1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PARAMETERS ====\n",
    "INPUT_DIR = \"C:/Users/adity/Documents/Pyhton_practice/streptomyces_model_2/dataset_raw/Streptomyces\"  # Raw dataset folder with subfolders for each class\n",
    "OUTPUT_DIR = \"C:/Users/adity/Documents/Pyhton_practice/streptomyces_model_2/Streptomyces/dataset_processed\"  # Where processed images will go\n",
    "IMG_SIZE = (512, 512)\n",
    "LBP_RADIUS = 3\n",
    "LBP_POINTS = 8 * LBP_RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a112011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Contents of dataset_raw: ['DSM_41600_image3.jpeg', 'DSM_41600_image4.jpeg', 'img_001.jpg', 'img_002.jpg', 'img_003.jpg', 'img_004.jpg', 'img_005.jpg', 'img_006.jpg', 'img_007.jpg', 'img_008.jpg', 'img_009.jpg', 'img_010.jpg', 'img_011.jpg', 'img_012.jpg', 'img_013.jpg', 'img_014.jpg', 'img_015.jpg', 'img_016.jpg', 'img_017.jpg', 'img_018.jpg', 'img_019.jpg', 'img_020.jpg', 'img_021.jpg', 'img_022.jpg', 'img_023.jpg', 'img_024.jpg', 'img_025.jpg', 'img_026.jpg', 'img_027.jpg', 'img_028.jpg', 'img_029.jpg', 'img_030.jpg', 'img_031.jpg', 'img_032.jpg', 'img_033.jpg', 'img_034.jpg', 'img_035.jpg', 'img_036.jpg', 'img_037.jpg', 'img_038.jpg', 'img_039.jpg', 'img_040.jpg', 'img_041.jpg', 'img_042.png', 'img_043.jpg', 'img_044.jpg', 'img_045.jpg', 'img_046.jpg', 'img_047.jpg', 'img_048.jpg', 'img_049.jpg', 'img_050.jpg', 'img_051.jpg', 'img_052.jpg', 'img_053.jpg', 'img_054.jpg', 'img_055.jpg', 'img_056.jpg', 'img_057.jpg', 'img_058.jpg', 'img_059.jpg', 'img_060.jpg', 'img_061.jpg', 'img_062.jpg', 'img_063.jpg', 'img_064.jpg', 'img_065.jpg', 'img_066.jpg', 'img_067.jpeg', 'img_068.jpg', 'img_069.jpg', 'img_070.jpg', 'img_071.jpg', 'img_072.jpeg', 'img_073.jpg', 'img_074.jpg', 'img_075.jpg', 'img_076.jpg', 'img_078.jpg', 'img_079.jpg', 'img_080.jpg', 'img_081.jpg', 'img_082.jpg', 'img_083.jpg', 'img_084.jpg', 'img_085.jpg', 'img_086.jpg', 'img_087.jpg', 'img_088.jpg', 'img_089.jpg', 'img_090.jpg', 'img_091.jpg', 'img_092.jpg', 'img_093.jpg', 'img_094.jpg', 'img_095.jpg', 'img_096.jpg', 'img_097.jpg', 'img_098.jpeg', 'img_099.jpg', 'img_100.jpg', 'img_101.jpg', 'img_102.jpg', 'img_103.jpg', 'img_104.jpg', 'img_105.jpg', 'img_106.jpg', 'img_107.jpg', 'img_108.jpg', 'img_109.jpg', 'img_110.jpg', 'img_111.webp', 'img_112.jpg', 'img_113.jpg', 'img_114.jpg', 'img_115.jpg', 'img_116.jpg', 'img_117.jpg', 'img_118.jpg', 'img_119.jpg', 'img_120.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Contents of dataset_raw:\", os.listdir(INPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63e2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CREATE OUTPUT DIR STRUCTURE ====\n",
    "classes = [cls for cls in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, cls))]\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, cls), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416d0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LBP Texture Function ====\n",
    "def generate_lbp (gray_img, radius = LBP_RADIUS, points = LBP_POINTS):\n",
    "    lbp = local_binary_pattern(gray_img, points, radius, method='uniform')\n",
    "    lbp = ((lbp - lbp.min())/ (lbp.max() - lbp.min()) * 255).astype(np.unit8)\n",
    "    return lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f05083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CLAHE on Saturation Channel ====\n",
    "def enhance_saturation_clahe(bgr_img):\n",
    "    # Convert image from BGR to HSV color space\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    # Create CLAHE object for local contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    # Apply CLAHE to the saturation channel\n",
    "    hsv[..., 1] = clahe.apply(hsv[..., 1])\n",
    "    # Convert back to BGR\n",
    "    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16b93926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== HED Edge Map using OpenCV DNN ====\n",
    "# ==== HED Edge Map using OpenCV DNN ====\n",
    "def generate_hed_edges(img):\n",
    "    proto = \"C:/Users/adity/Documents/Pyhton_practice/hed_model/deploy.prototxt\"  # Path to model architecture\n",
    "    weights = \"C:/Users/adity/Documents/Pyhton_practice/hed_model/hed_pretrained_bsds.caffemodel\"  # Path to pretrained weights\n",
    "\n",
    "    if not os.path.exists(proto) or not os.path.exists(weights):\n",
    "        print(\"‚ùå HED model files not found.\")\n",
    "        return np.zeros(IMG_SIZE, dtype=np.uint8)  # Return blank if model is missing\n",
    "\n",
    "    net = cv2.dnn.readNetFromCaffe(proto, weights)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=1.0, size=(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "                                 mean=(104.00698793, 116.66876762, 122.67891434), swapRB=False, crop=False)\n",
    "    net.setInput(blob)\n",
    "    hed = net.forward()\n",
    "    hed = cv2.resize(hed[0, 0], IMG_SIZE)\n",
    "    hed = (255 * hed).astype(np.uint8)\n",
    "    return hed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9df19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LBP + CLAHE-only images saved in: C:/Users/adity/Documents/Pyhton_practice/streptomyces_model_2/Streptomyces/dataset_processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cls in tqdm(classes, desc=\"Processing classes\"):\n",
    "    class_path = os.path.join(INPUT_DIR, cls)\n",
    "    save_path = os.path.join(OUTPUT_DIR, cls)\n",
    "\n",
    "    for fname in os.listdir(class_path):\n",
    "        print(f\"üîç Found file: {fname} in class: {cls}\")\n",
    "        if not fname.lower().endswith(('.JPG', '.JPEG', '.PNG')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(class_path, fname)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "           print(f\"‚ö†Ô∏è Could not read image: {img_path}\")\n",
    "           continue\n",
    "        else:\n",
    "            print(f\"üì∏ Image loaded: {img.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = generate_lbp(gray)\n",
    "        clahe_img = enhance_saturation_clahe(img)\n",
    "        hsv = cv2.cvtColor(clahe_img, cv2.COLOR_BGR2HSV)\n",
    "        sat_clahe = hsv[..., 1]\n",
    "\n",
    "       # Minimal test: LBP + CLAHE (duplicate for 3rd channel)\n",
    "        composite = cv2.merge([lbp, sat_clahe, sat_clahe])\n",
    "\n",
    "        # Debug info\n",
    "        print(f\"üß™ Checking composite types: LBP({lbp.dtype}), CLAHE({sat_clahe.dtype})\")\n",
    "        print(f\"üß™ Composite shape: {composite.shape}, dtype: {composite.dtype}, max: {composite.max()}\")\n",
    "\n",
    "        composite = np.clip(composite, 0, 255).astype(np.uint8)\n",
    "\n",
    "        save_name = os.path.splitext(fname)[0] + '_prep.png'\n",
    "        save_file = os.path.join(save_path, save_name)\n",
    "        success = cv2.imwrite(save_file, composite)\n",
    "\n",
    "        if not success:\n",
    "            print(f\"‚ùå Failed to save image: {save_file}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Saved: {save_file}\")\n",
    "\n",
    "print(\"‚úÖ LBP + CLAHE-only images saved in:\", OUTPUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c5f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "folder = 'C:/Users/adity/Documents/Pyhton_practice/streptomyces_model_2/dataset_processed/Streptomyces'  # or micromonospora\n",
    "files = [f for f in os.listdir(folder) if f.endswith('_prep.png')]\n",
    "\n",
    "for f in files[:5]:\n",
    "    path = os.path.join(folder, f)\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
